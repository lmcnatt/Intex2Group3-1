{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('intex2.db')\n",
    "cursor = conn.cursor()\n",
    "read_sql = \"SELECT P.ProductId, P.Name, P.Description, CL.Rating, O.CustomerId FROM Products P\\\n",
    "    join CartLine CL on CL.ProductId = P.ProductId join Orders O on O.OrderId = CL.OrderId\"\n",
    "df = pd.read_sql_query(read_sql, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_ratings(df, count_column, min=2, messages=True):\n",
    "  value_counts = df[count_column].value_counts()\n",
    "  keep_list = value_counts[value_counts >= min]\n",
    "  df = df.loc[df[count_column].isin(keep_list.index)]\n",
    "\n",
    "  if messages: print(df[count_column].value_counts())\n",
    "\n",
    "  return df\n",
    "df.drop_duplicates(subset=['CustomerId', 'ProductId'], keep='first', inplace=True)\n",
    "#We are keeping the first because ratings should be based on intial difficulty or enjoyment\n",
    "df_collab = min_ratings(df, 'ProductId', min=100, messages=False) \n",
    "#We set this value low so only new products use collaborative since content isnt very accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this does the collaborative filtering\n",
    "df_products = df.groupby('ProductId').agg({'Name':'max',\n",
    "                                       'Description':'max',\n",
    "                                       'Rating':'count'})\n",
    "def create_matrix(df, user, item, rating):\n",
    "  import numpy as np\n",
    "  from scipy.sparse import csr_matrix\n",
    "\n",
    "  U = df[user].nunique()  # Number of users for the matrix\n",
    "  I = df[item].nunique()  # Number of items for the matrix\n",
    "\n",
    "  # Map user and item IDs to matrix indices\n",
    "  user_mapper = dict(zip(np.unique(df[user]), list(range(U))))\n",
    "  item_mapper = dict(zip(np.unique(df[item]), list(range(I))))\n",
    "\n",
    "  # Map matrix indices back to IDs\n",
    "  user_inv_mapper = dict(zip(list(range(U)), np.unique(df[user])))\n",
    "  item_inv_mapper = dict(zip(list(range(I)), np.unique(df[item])))\n",
    "\n",
    "  # Create a list of index values for the csr_matrix for users and movies\n",
    "  user_index = [user_mapper[i] for i in df[user]]\n",
    "  item_index = [item_mapper[i] for i in df[item]]\n",
    "\n",
    "  # Build the final matrix which will look like: (itemId, userId) rating\n",
    "  X = csr_matrix((df[rating], (item_index, user_index)), shape=(I, U))\n",
    "\n",
    "  return X, user_mapper, item_mapper, user_inv_mapper, item_inv_mapper\n",
    "\n",
    "def collab_recommend(itemId, X, item_mapper, item_inv_mapper, k, metric='cosine', messages=True):\n",
    "  from sklearn.neighbors import NearestNeighbors\n",
    "  import numpy as np\n",
    "\n",
    "  rec_ids = []                # Make a list for the recommended item IDs we'll get later\n",
    "  item = item_mapper[itemId]  # Get the index of the item ID passed into the function\n",
    "  item_vector = X[item]       # Get the vector of user ratings for the item ID passed into the function\n",
    "\n",
    "  # Fit the clustering algorithm based on the user-item matrix X\n",
    "  knn = NearestNeighbors(n_neighbors=k+1, algorithm=\"brute\", metric=metric).fit(X)\n",
    "\n",
    "  # Call the trained knn cluster model to return the nearest neighbors of the item_vector passed in\n",
    "  rec = knn.kneighbors(item_vector.reshape(1,-1), return_distance=True)\n",
    "  rec_indeces = rec[1][0]     # Parse out the list of indeces of the recommended items\n",
    "  rec_distances = rec[0][0]   # Parse out the recommendation strength calculated as the distance from the cluster center\n",
    "  rec_distances = np.delete(rec_distances, 0) # Drop the first number in the list because it is the distance of itemId from itself\n",
    "\n",
    "  # We need to replace the recommended item indeces with their original item IDs\n",
    "  for i in range(1, knn.n_neighbors): # n_neighbors is the number of neighbors to return\n",
    "    rec_ids.append(item_inv_mapper[rec_indeces[i]])\n",
    "\n",
    "  # It may help to see what this is. The distance list is first and the recommended item indeces are second\n",
    "  if messages:\n",
    "    print(f'List of recommended item indeces:\\n{rec_indeces}\\n')\n",
    "    print(f'List of recommended item IDs:\\n{rec_ids}\\n')\n",
    "    print(f'List of recommended item similarity to selected item:\\n{rec_distances}\\n')\n",
    "\n",
    "  # Return two lists: the original item IDs of the recommendations and their similarity scores\n",
    "  return rec_ids, rec_distances\n",
    "\n",
    "X, user_mapper, item_mapper, user_inv_mapper, item_inv_mapper = create_matrix(df_collab, 'CustomerId', 'ProductId', 'Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This starts Content filtering\n",
    "def tfidf_matrix(df, similarity_col):\n",
    "  import numpy as np\n",
    "  from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "  from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "  # Create a TfidfVectorizer and Remove stopwords\n",
    "  tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "  # Fit and transform the data to a tfidf matrix\n",
    "  tfidf_matrix = tfidf.fit_transform(df[similarity_col])\n",
    "\n",
    "  # Build the final matrix which will look like: (movieId, userId) rating\n",
    "  cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "  return cosine_sim\n",
    "def content_recommend(item_id, sim_matrix, n=10, messages=True):\n",
    "  if item_id > sim_matrix.shape[0]:  # Add some error checking for robustness\n",
    "    print(f\"Item {item_id} is not in the similarity matrix you provided with shape: {sim_matrix.shape}\")\n",
    "    return\n",
    "\n",
    "  # Get the pairwise similarity scores of all movies with that movie\n",
    "  sim_scores = list(enumerate(sim_matrix[item_id]))\n",
    "\n",
    "  # Sort the items based on the similarity scores\n",
    "  sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "  # Get the scores of the n most similar items; start at 1 so that it skips itself\n",
    "  top_similar = sim_scores[1:n+1]\n",
    "\n",
    "  # Put the recommended item indices and similarity scores together in a dictionary using comprehension\n",
    "  rec_dict = {i[0]:i[1] for i in top_similar}\n",
    "\n",
    "  if messages:\n",
    "    print(f\"The top recommended item IDs are: {list(rec_dict.keys())}\")\n",
    "    print(f\"Their similarity scores are:\\t  {list(rec_dict.values())}\")\n",
    "\n",
    "  # Return the top n most similar items\n",
    "  return rec_dict\n",
    "\n",
    "df_products.reset_index(inplace=True)\n",
    "df_products['similarity'] = df_products['Name'] + \" \" + df_products['Description']\n",
    "sim_matrix = tfidf_matrix(df_products, 'similarity')\n",
    "df_products.drop(columns=['similarity'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This brings them together\n",
    "threshold = 100\n",
    "\n",
    "df_recommendations = pd.DataFrame(columns=['RecId', 'Rec1', 'Rec2', 'Rec3', 'Rec4', 'Rec5',\n",
    "                                           'Rec6', 'Rec7', 'Rec8', 'Rec9', 'Rec10'])\n",
    "\n",
    "for row in df_products.itertuples():\n",
    "  if row.Rating >= threshold:\n",
    "    rec_ids, rec_distances = collab_recommend(row.ProductId, X, item_mapper, item_inv_mapper, k=10, messages=False)\n",
    "  else:\n",
    "    recommend_dict = content_recommend(row[0], sim_matrix, n=10, messages=False)\n",
    "    rec_ids = list(recommend_dict.keys())\n",
    "    rec_distances = list(recommend_dict.values())\n",
    "\n",
    "  df_recommendations.loc[row[0]] = [row.ProductId, rec_ids[0], rec_ids[1], rec_ids[2], rec_ids[3], rec_ids[4], rec_ids[5], rec_ids[6], rec_ids[7], rec_ids[8], rec_ids[9]]\n",
    "\n",
    "df_recommendations.to_sql(name=\"Recommendations\", con=conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 809. MiB for an array with shape (29134, 29134) and data type bool",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AgglomerativeClustering\n\u001b[0;32m      7\u001b[0m distance_matrix \u001b[38;5;241m=\u001b[39m gower\u001b[38;5;241m.\u001b[39mgower_matrix(df)\n\u001b[1;32m----> 8\u001b[0m agg \u001b[38;5;241m=\u001b[39m \u001b[43mAgglomerativeClustering\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinkage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maverage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistance_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m agg\u001b[38;5;241m.\u001b[39mlabels_\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mitertuples():\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\cluster\\_agglomerative.py:980\u001b[0m, in \u001b[0;36mAgglomerativeClustering.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the hierarchical clustering from features, or distance matrix.\u001b[39;00m\n\u001b[0;32m    963\u001b[0m \n\u001b[0;32m    964\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;124;03m    Returns the fitted instance.\u001b[39;00m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    979\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, ensure_min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 980\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\cluster\\_agglomerative.py:1066\u001b[0m, in \u001b[0;36mAgglomerativeClustering._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1062\u001b[0m distance_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistance_threshold\n\u001b[0;32m   1064\u001b[0m return_distance \u001b[38;5;241m=\u001b[39m (distance_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_distances\n\u001b[1;32m-> 1066\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmemory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree_builder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnectivity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnectivity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1072\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1073\u001b[0m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_connected_components_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_leaves_, parents) \u001b[38;5;241m=\u001b[39m out[\n\u001b[0;32m   1074\u001b[0m     :\u001b[38;5;241m4\u001b[39m\n\u001b[0;32m   1075\u001b[0m ]\n\u001b[0;32m   1077\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_distance:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\joblib\\memory.py:353\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\cluster\\_agglomerative.py:711\u001b[0m, in \u001b[0;36m_average_linkage\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_average_linkage\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    710\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinkage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 711\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlinkage_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\cluster\\_agglomerative.py:585\u001b[0m, in \u001b[0;36mlinkage_tree\u001b[1;34m(X, connectivity, n_clusters, linkage, affinity, return_distance)\u001b[0m\n\u001b[0;32m    583\u001b[0m     out \u001b[38;5;241m=\u001b[39m _hierarchical\u001b[38;5;241m.\u001b[39msingle_linkage_label(mst)\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 585\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mhierarchy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinkage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinkage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maffinity\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    586\u001b[0m children_ \u001b[38;5;241m=\u001b[39m out[:, :\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_distance:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\cluster\\hierarchy.py:1019\u001b[0m, in \u001b[0;36mlinkage\u001b[1;34m(y, method, metric, optimal_ordering)\u001b[0m\n\u001b[0;32m   1016\u001b[0m     distance\u001b[38;5;241m.\u001b[39mis_valid_y(y, throw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(np\u001b[38;5;241m.\u001b[39mdiag(y), \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m-> 1019\u001b[0m             xp\u001b[38;5;241m.\u001b[39mall(\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(y, y\u001b[38;5;241m.\u001b[39mT)):\n\u001b[0;32m   1020\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe symmetric non-negative hollow observation \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1021\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatrix looks suspiciously like an uncondensed \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1022\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance matrix\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1023\u001b[0m                       ClusterWarning, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m   1024\u001b[0m     y \u001b[38;5;241m=\u001b[39m distance\u001b[38;5;241m.\u001b[39mpdist(y, metric)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 809. MiB for an array with shape (29134, 29134) and data type bool"
     ]
    }
   ],
   "source": [
    "#This determines the cluster to aid recommendations for new users\n",
    "read_sql = \"SELECT * from Customers\"\n",
    "df = pd.read_sql_query(read_sql, conn)\n",
    "df.drop(columns=['Cluster', 'ClusterRecId'], inplace=True)\n",
    "import gower\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "distance_matrix = gower.gower_matrix(df)\n",
    "agg = AgglomerativeClustering(n_clusters=2, linkage=\"average\").fit(distance_matrix)\n",
    "df['Cluster'] = agg.labels_\n",
    "for row in df.itertuples():\n",
    "    curr_cluster = row['Cluster']\n",
    "    read_sql = \"SELECT CL.ProductId, sum(CL.Quantity) as quantity from CartLine CL join Orders O on O.OrderId = CL.OrderId \\\n",
    "    join Customer C on C.CustomerId = O.CustomerId where C.Cluster = {curr_cluster} group by CL.ProductId\"\n",
    "    df_rec = pd.read_sql_query(read_sql, conn)\n",
    "    df_rec.sort_values(by='quantity', ascending=False, inplace=True)\n",
    "    top_productid = df_rec.iloc[0]['productid']\n",
    "    row['ClusterRecId'] = top_productid\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products = pd.read_csv(r'\"C:\\Users\\gooch\\Downloads\\INTEX W24 Dataset.xlsx - Products.csv\"')\n",
    "df_products.to_sql(name=\"Products\", con=conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
