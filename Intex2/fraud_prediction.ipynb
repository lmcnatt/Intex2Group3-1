{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gooch\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\gooch\\AppData\\Local\\Temp\\ipykernel_13260\\1469616893.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df[label] = y\n",
      "C:\\Users\\gooch\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No known ways to retrieve the number of classes for class <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 187\u001b[0m\n\u001b[0;32m    185\u001b[0m model \u001b[38;5;241m=\u001b[39m fit_cv_model(new_5_percent_df, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, label\u001b[38;5;241m=\u001b[39mlabel, messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    186\u001b[0m df_reduced \u001b[38;5;241m=\u001b[39m select_features(new_5_percent_df\u001b[38;5;241m.\u001b[39mcopy(), label\u001b[38;5;241m=\u001b[39mlabel, model\u001b[38;5;241m=\u001b[39mmodel, messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 187\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mfit_cv_model_expanded\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_reduced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfraud_onnx_model.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    189\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(model\u001b[38;5;241m.\u001b[39mSerializeToString())\n",
      "Cell \u001b[1;32mIn[35], line 175\u001b[0m, in \u001b[0;36mfit_cv_model_expanded\u001b[1;34m(df, label, k, r, repeat, random_state)\u001b[0m\n\u001b[0;32m    173\u001b[0m best_model \u001b[38;5;241m=\u001b[39m df_fit\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    174\u001b[0m initial_type \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat_input\u001b[39m\u001b[38;5;124m'\u001b[39m, FloatTensorType([\u001b[38;5;28;01mNone\u001b[39;00m, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]]))]\n\u001b[1;32m--> 175\u001b[0m onnx_model \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_sklearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m onnx_model\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skl2onnx\\convert.py:190\u001b[0m, in \u001b[0;36mconvert_sklearn\u001b[1;34m(model, name, initial_types, doc_string, target_opset, custom_conversion_functions, custom_shape_calculators, custom_parsers, options, intermediate, white_op, black_op, final_types, dtype, naming, model_optim, verbose)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[convert_sklearn] parse_sklearn_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 190\u001b[0m topology \u001b[38;5;241m=\u001b[39m \u001b[43mparse_sklearn_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_opset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_conversion_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_shape_calculators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_parsers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhite_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhite_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblack_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblack_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinal_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnaming\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;66;03m# Convert our Topology object into ONNX. The outcome is an ONNX model.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m options \u001b[38;5;241m=\u001b[39m _process_options(model, options)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skl2onnx\\_parse.py:836\u001b[0m, in \u001b[0;36mparse_sklearn_model\u001b[1;34m(model, initial_types, target_opset, custom_conversion_functions, custom_shape_calculators, custom_parsers, options, white_op, black_op, final_types, naming)\u001b[0m\n\u001b[0;32m    833\u001b[0m     raw_model_container\u001b[38;5;241m.\u001b[39madd_input(variable)\n\u001b[0;32m    835\u001b[0m \u001b[38;5;66;03m# Parse the input scikit-learn model as a Topology object.\u001b[39;00m\n\u001b[1;32m--> 836\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mparse_sklearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_parsers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_parsers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_types\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[38;5;66;03m# The object raw_model_container is a part of the topology we're\u001b[39;00m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;66;03m# going to return. We use it to store the outputs of the\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;66;03m# scikit-learn's computational graph.\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_types \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(final_types) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(outputs):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skl2onnx\\_parse.py:746\u001b[0m, in \u001b[0;36mparse_sklearn\u001b[1;34m(scope, model, inputs, custom_parsers, final_types)\u001b[0m\n\u001b[0;32m    743\u001b[0m             o\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[1;32m--> 746\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_parse_sklearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_parsers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_parsers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m res:\n\u001b[0;32m    748\u001b[0m     r\u001b[38;5;241m.\u001b[39minit_status(is_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skl2onnx\\_parse.py:677\u001b[0m, in \u001b[0;36m_parse_sklearn\u001b[1;34m(scope, model, inputs, custom_parsers, alias)\u001b[0m\n\u001b[0;32m    673\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m custom_parsers[tmodel](\n\u001b[0;32m    674\u001b[0m         scope, model, inputs, custom_parsers\u001b[38;5;241m=\u001b[39mcustom_parsers\n\u001b[0;32m    675\u001b[0m     )\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tmodel \u001b[38;5;129;01min\u001b[39;00m sklearn_parsers_map:\n\u001b[1;32m--> 677\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43msklearn_parsers_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtmodel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_parsers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_parsers\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pipeline\u001b[38;5;241m.\u001b[39mPipeline):\n\u001b[0;32m    681\u001b[0m     parser \u001b[38;5;241m=\u001b[39m sklearn_parsers_map[pipeline\u001b[38;5;241m.\u001b[39mPipeline]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skl2onnx\\_parse.py:545\u001b[0m, in \u001b[0;36m_parse_sklearn_classifier\u001b[1;34m(scope, model, inputs, custom_parsers)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_class_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    542\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOption \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_class_labels\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with option \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzipmap\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    543\u001b[0m     )\n\u001b[1;32m--> 545\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_zipmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzipmap\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobability_tensor\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skl2onnx\\_parse.py:457\u001b[0m, in \u001b[0;36m_apply_zipmap\u001b[1;34m(zipmap_options, scope, model, input_type, probability_tensor)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    456\u001b[0m     zipmap_operator \u001b[38;5;241m=\u001b[39m scope\u001b[38;5;241m.\u001b[39mdeclare_local_operator(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSklearnZipMap\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 457\u001b[0m     classes \u001b[38;5;241m=\u001b[39m \u001b[43mget_label_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m zipmap_operator\u001b[38;5;241m.\u001b[39minputs \u001b[38;5;241m=\u001b[39m probability_tensor\n\u001b[0;32m    460\u001b[0m label_type \u001b[38;5;241m=\u001b[39m Int64TensorType([\u001b[38;5;28;01mNone\u001b[39;00m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skl2onnx\\common\\utils_classifier.py:44\u001b[0m, in \u001b[0;36mget_label_classes\u001b[1;34m(scope, op, node_names)\u001b[0m\n\u001b[0;32m     42\u001b[0m     classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(op\u001b[38;5;241m.\u001b[39my_))))\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo known ways to retrieve the number of classes for class \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(op)\n\u001b[0;32m     47\u001b[0m     )\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m classes\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No known ways to retrieve the number of classes for class <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import onnx # not used but can be used to inspect and manipulate saved onnx model\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "conn = sqlite3.connect('intex2.db')\n",
    "cursor = conn.cursor()\n",
    "read_sql = \"SELECT * from Orders\"\n",
    "df = pd.read_sql_query(read_sql, conn)\n",
    "df\n",
    "\n",
    "\n",
    "#This has all the functions\n",
    "def bin_categories(df, features=[], cutoff=0.05, replace_with='Other', messages=False):\n",
    "\n",
    "  import pandas as pd\n",
    "\n",
    "  if len(features) == 0: features = df.columns\n",
    "\n",
    "  for feat in features:\n",
    "    if feat in df.columns:\n",
    "      if not pd.api.types.is_numeric_dtype(df[feat]):\n",
    "        other_list = df[feat].value_counts()[df[feat].value_counts() / df.shape[0] < cutoff].index\n",
    "        df.loc[df[feat].isin(other_list), feat] = replace_with\n",
    "        if messages: print(f'{feat} has been binned by setting {other_list} to {replace_with}')\n",
    "    else:\n",
    "      if messages: print(f'{feat} not found in the DataFrame provided. No binning performed')\n",
    "\n",
    "  return df\n",
    "\n",
    "def Xandy(df, label):\n",
    "    import pandas as pd\n",
    "    y = df[label]\n",
    "    X = df.drop(columns=[label])\n",
    "    return X, y\n",
    "\n",
    "def dummy_code(X):\n",
    "    import pandas as pd\n",
    "    X = pd.get_dummies(X.copy(), drop_first=True)\n",
    "    return X\n",
    "\n",
    "def missing_data(df, label, row_thresh = 0.7, col_thresh = 0.9, random=False, random_state=3):\n",
    "    import pandas as pd\n",
    "    df.dropna(axis='rows', subset=[label], inplace=True)\n",
    "    df.dropna(axis='columns', thresh=1, inplace=True)\n",
    "    df.dropna(axis='rows', thresh=1, inplace=True)\n",
    "    df.dropna(axis='columns', thresh=round(df.shape[0] * row_thresh), inplace=True)\n",
    "    df.dropna(axis='rows', thresh=round(df.shape[1] * col_thresh), inplace=True)\n",
    "    #impute values\n",
    "    if df.isna().sum().sum() > 0:\n",
    "        from sklearn.experimental import enable_iterative_imputer\n",
    "        from sklearn.impute import IterativeImputer, KNNImputer\n",
    "        X, y = Xandy(df, label)\n",
    "        X = dummy_code(X.copy())\n",
    "        if random: random_state = 0\n",
    "        imp = IterativeImputer(max_iter=10, random_state=random_state)\n",
    "        X = pd.DataFrame(imp.fit_transform(X), columns = X.columns, index = X.index)\n",
    "        df = X.merge(y, left_index=True, right_index=True)\n",
    "    else:\n",
    "        X, y = Xandy(df, label)\n",
    "        X = dummy_code(X.copy())\n",
    "        df = X.merge(y, left_index=True, right_index=True)\n",
    "    return df\n",
    "\n",
    "def fit_cv_model(df, label, k=5, repeat=True, random=False, random_state=3, messages=False):\n",
    "    from sklearn.model_selection import KFold, RepeatedKFold, cross_val_score\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    X, y = Xandy(df, label)\n",
    "    X = dummy_code(X.copy())\n",
    "    if repeat:\n",
    "        cv = RepeatedKFold(n_splits=k, n_repeats=5)\n",
    "    else:\n",
    "        cv = KFold(n_splits=k)\n",
    "    if random==True: random_state = 0\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "    from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "    model_rfc = RandomForestClassifier(random_state=random_state)\n",
    "    model_ridge = RidgeClassifier(random_state=random_state)\n",
    "    model_gbc = GradientBoostingClassifier(random_state=random_state)\n",
    "    model_log = LogisticRegression(random_state=random_state, max_iter=10000)\n",
    "    scores_rfc = cross_val_score(model_rfc, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    scores_ridge = cross_val_score(model_ridge, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    scores_gbc = cross_val_score(model_gbc, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    scores_log = cross_val_score(model_log, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    if messages == True:\n",
    "        print(f'Accuracy (RandomForest):\\t{np.mean(scores_rfc)}')\n",
    "        print(f'Accuracy (Ridge):\\t{np.mean(scores_ridge)}')\n",
    "        print(f'Accuracy (GradientBoosting):\\t{np.mean(scores_gbc)}')\n",
    "        print(f'Accuracy (Log):\\t{np.mean(scores_log)}')\n",
    "    scores = {np.mean(scores_rfc):model_rfc, \n",
    "            np.mean(scores_gbc):model_gbc, \n",
    "            np.mean(scores_ridge):model_ridge, \n",
    "            np.mean(scores_log):model_log }    \n",
    "    return scores[max(scores.keys())].fit(X, y)\n",
    "\n",
    "def select_features(df, label, model, messages=True):\n",
    "  from sklearn.feature_selection import SelectFromModel\n",
    "  import pandas as pd\n",
    "\n",
    "  y = df[label]\n",
    "  X = df.drop(columns=[label])\n",
    "  X = pd.get_dummies(X.copy(), drop_first=True)\n",
    "\n",
    "  sel = SelectFromModel(model, prefit=True)\n",
    "  sel.transform(X)\n",
    "\n",
    "  columns = list(X.columns[sel.get_support()])\n",
    "  new_df = X[columns]\n",
    "  new_df[label] = y\n",
    "  return new_df\n",
    "\n",
    "def fit_cv_model_expanded(df, label, k=10, r=5, repeat=True, random_state=1):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import KFold, RepeatedKFold, cross_val_score\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "    from sklearn.svm import SVC, LinearSVC\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from xgboost import XGBClassifier\n",
    "\n",
    "    # Assuming Xandy is a function to split features (X) and target (y)\n",
    "    X, y = Xandy(df, label)\n",
    "\n",
    "    if repeat:\n",
    "        cv = RepeatedKFold(n_splits=k, n_repeats=r, random_state=random_state)\n",
    "    else:\n",
    "        cv = KFold(n_splits=k, random_state=random_state, shuffle=True)\n",
    "    \n",
    "    fit = {}    # Use this to store each of the fit metrics\n",
    "    models = {} # Use this to store each of the models\n",
    "\n",
    "    # Create the model objects\n",
    "    model_logistic = LogisticRegression(random_state=random_state)\n",
    "    model_rf = RandomForestClassifier(random_state=random_state)\n",
    "    model_gb = GradientBoostingClassifier(random_state=random_state)\n",
    "    model_ab = AdaBoostClassifier(n_estimators=100, random_state=random_state)\n",
    "    model_svc = SVC(random_state=random_state)\n",
    "    model_lsvc = LinearSVC(random_state=random_state)\n",
    "    model_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    model_xgb = XGBClassifier(n_estimators=1000, max_depth=7, learning_rate=0.1, subsample=0.7, colsample_bytree=0.8, random_state=random_state)\n",
    "    model_mlp = MLPClassifier(max_iter=1000, random_state=random_state)\n",
    "\n",
    "    # Fit a cross-validated accuracy score and add it to the dict\n",
    "    fit['Logistic Regression'] = np.mean(cross_val_score(model_logistic, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    fit['Random Forest'] = np.mean(cross_val_score(model_rf, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    fit['Gradient Boosting'] = np.mean(cross_val_score(model_gb, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    fit['AdaBoost'] = np.mean(cross_val_score(model_ab, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    fit['SVM'] = np.mean(cross_val_score(model_svc, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    fit['Linear SVM'] = np.mean(cross_val_score(model_lsvc, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    fit['KNN'] = np.mean(cross_val_score(model_knn, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    fit['XGBoost'] = np.mean(cross_val_score(model_xgb, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    fit['Neural Network'] = np.mean(cross_val_score(model_mlp, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "\n",
    "    # Add the model to another dict; make sure the keys have the same names as the list above\n",
    "    models['Logistic Regression'] = model_logistic\n",
    "    models['Random Forest'] = model_rf\n",
    "    models['Gradient Boosting'] = model_gb\n",
    "    models['AdaBoost'] = model_ab\n",
    "    models['SVM'] = model_svc\n",
    "    models['Linear SVM'] = model_lsvc\n",
    "    models['KNN'] = model_knn\n",
    "    models['XGBoost'] = model_xgb\n",
    "    models['Neural Network'] = model_mlp\n",
    "\n",
    "    # Add the fit dictionary to a new DataFrame, sort, extract the top row, use it to retrieve the model object from the models dictionary\n",
    "    df_fit = pd.DataFrame({'Accuracy': fit})\n",
    "    df_fit.sort_values(by=['Accuracy'], ascending=False, inplace=True)\n",
    "    best_model = df_fit.index[0]\n",
    "    initial_type = [('float_input', FloatTensorType([None, X.shape[1]]))]\n",
    "    onnx_model = convert_sklearn(models[best_model], initial_types=initial_type)\n",
    "\n",
    "    return onnx_model\n",
    "\n",
    "\n",
    "\n",
    "#We are not limiting down to CVC and Online only because if there is other types of transactions those need to be known\n",
    "new_5_percent_df = bin_categories(df.copy(), cutoff=0.05)\n",
    "label = 'Fraud'\n",
    "new_5_percent_df = missing_data(new_5_percent_df, label)\n",
    "model = fit_cv_model(new_5_percent_df, k=5, label=label, messages=False)\n",
    "df_reduced = select_features(new_5_percent_df.copy(), label=label, model=model, messages=False)\n",
    "model = fit_cv_model_expanded(df_reduced, k=5, label=label)\n",
    "with open(\"fraud_onnx_model.onnx\", \"wb\")as f:\n",
    "    f.write(model.SerializeToString())\n",
    "\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
